Total docs: 3400
Distinct tokens: 17731
Docs processed: 3400
Total words processed: 513973


Doc-freqs length: 17731
Look for token counts in the range: (0, 170)
Analysis intervals: [(1.0, 17.0), (18.0, 34.0), (35.0, 51.0), (52.0, 68.0), (69.0, 85.0), (86.0, 102.0), (103.0, 119.0), (120.0, 136.0), (137.0, 153.0), (154.0, 170.0)]
Documents-frequencies by interval: [15378, 858, 363, 236, 143, 121, 91, 58, 43, 51]
Relevant marks: [0.00029412 0.00529412 0.01029412 0.01529412 0.02029412 0.02529412
 0.03029412 0.03529412 0.04029412]
Relevant frequencies for each bin: [15378, 858, 363, 236, 143, 121, 91, 58, 43]
No. of bins: 9
Histogram generated and saved


Finish vocabulary analysis: (0 for no, 1 for yes): 0
Do you want to filter tokens by minimum DF? 1
Insert the minimum DF to filter (range: 0-1): 0.005
Do you want to filter tokens by maximum DF? 0


Using
	No below: 17 documents
	No above: 1.0 of total corpus
Distinct tokens after filtering: 2428
Saved filtered dictionary instance to ./images/dictionary/dictionary_pt_min_df_0.005_max_df_1.0.gdict