Total docs: 32092
Distinct tokens: 29117
Docs processed: 32092
Total words processed: 2667022


Doc-freqs length: 29117
Look for token counts in the range: (0, 1604)
Analysis intervals: [(1.0, 160.4), (161.4, 320.8), (321.8, 481.20000000000005), (482.20000000000005, 641.6), (642.6, 802.0), (803.0, 962.4000000000001), (963.4000000000001, 1122.8), (1123.8, 1283.2), (1284.2, 1443.6000000000001), (1444.6000000000001, 1604.0)]
Documents-frequencies by interval: [27603, 554, 242, 146, 106, 61, 51, 45, 29, 30]
Relevant marks: [3.11604138e-05 5.02929079e-03 1.00274212e-02 1.50255515e-02
 2.00236819e-02 2.50218123e-02 3.00199427e-02 3.50180730e-02
 4.00162034e-02]
Relevant frequencies for each bin: [27603, 554, 242, 146, 106, 61, 51, 45, 29]
No. of bins: 9
Histogram generated and saved


Finish vocabulary analysis: (0 for no, 1 for yes): 0
Do you want to filter tokens by minimum DF? 1
Insert the minimum DF to filter (range: 0-1): 0.005
Do you want to filter tokens by maximum DF? 0


Using
	No below: 160 documents
	No above: 1.0 of total corpus
Distinct tokens after filtering: 1524
Saved filtered dictionary instance to ./images/dictionary_en_min_df_0.005_max_df_1.0.gdict
